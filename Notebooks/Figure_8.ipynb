{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eCUN1k7-HqS1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679390931914,"user_tz":-60,"elapsed":814,"user":{"displayName":"Keon Chen","userId":"05913365539252419352"}},"outputId":"6405c529-f9e5-45bc-b3e0-92d98de3d746"},"outputs":[{"output_type":"stream","name":"stdout","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]}],"source":["# Setup\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from torch.utils.data import TensorDataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torchsummary import summary\n","\n","import torchvision.datasets as datasets\n","from torchvision import datasets, models, transforms\n","from torch.autograd import Variable\n","\n","%load_ext tensorboard"]},{"cell_type":"code","source":["# HyperParameters\n","\n","num_epochs = 1\n","batch_size_train = 32\n","batch_size_test = 32\n","learning_rate = 0.01\n","momentum = 0.5"],"metadata":{"id":"9fec6VzRf0TM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare raw dataset\n","import zipfile\n","from google.colab import drive\n","\n","drive_dir = '/content/gdrive'\n","drive.mount(drive_dir)\n","work_dir = f'{drive_dir}/My Drive/Reproduction_DL'\n","\n","\n","!ls \"/content/gdrive/My Drive/Reproduction_DL/ISIC\"\n","\n","\n","dataset_list = ['ISBI2016_ISIC_Part1_Test_Data.zip', 'ISBI2016_ISIC_Part1_Test_GroundTruth.zip', 'ISBI2016_ISIC_Part1_Training_Data.zip', 'ISBI2016_ISIC_Part1_Training_GroundTruth.zip']\n","\n","for d in dataset_list:\n","  zip_ref = zipfile.ZipFile(f'{work_dir}/ISIC/{d}', 'r')\n","  # folder_to_extract = d.strip('.zip')\n","  zip_ref.extractall(f'{work_dir}/ISIC/')\n","  zip_ref.close()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9s_DSPlD4qi4","executionInfo":{"status":"ok","timestamp":1679500856602,"user_tz":-60,"elapsed":25618,"user":{"displayName":"Keon Chen","userId":"05913365539252419352"}},"outputId":"299d7b8b-3c95-47b0-bd2b-240ba0654386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","ISBI2016_ISIC_Part1_Test_Data\n","ISBI2016_ISIC_Part1_Test_Data.zip\n","ISBI2016_ISIC_Part1_Test_GroundTruth\n","ISBI2016_ISIC_Part1_Test_GroundTruth.zip\n","ISBI2016_ISIC_Part1_Training_Data\n","ISBI2016_ISIC_Part1_Training_Data.zip\n","ISBI2016_ISIC_Part1_Training_GroundTruth\n","ISBI2016_ISIC_Part1_Training_GroundTruth.zip\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cMwTeF8AKsDt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the ISIC dataset (assumes it's already preprocessed)\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","train_dataset = datasets.ImageFolder(\"path/to/train_data\", transform=train_transform)\n","val_dataset = datasets.ImageFolder(\"path/to/val_data\", transform=val_transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True, num_workers=4)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size_test, shuffle=False, num_workers=4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"ZJm05lzbgjZN","executionInfo":{"status":"error","timestamp":1679391878011,"user_tz":-60,"elapsed":1475,"user":{"displayName":"Keon Chen","userId":"05913365539252419352"}},"outputId":"e3ea7697-23ed-406c-879b-67001458b328"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-3b1a6270eee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path/to/train_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path/to/val_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/train_data'"]}]},{"cell_type":"code","source":["# Load Model\n","\n","model = models.vgg13(pretrained=True)\n","\n","# Make sure the input type and the weight type be on the same device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","input_size=(3, 244, 244)\n","summary(model, input_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r8VamJflkiSz","executionInfo":{"status":"ok","timestamp":1679392869346,"user_tz":-60,"elapsed":2334,"user":{"displayName":"Keon Chen","userId":"05913365539252419352"}},"outputId":"617694e8-fccc-40bb-8221-89ed3e6766a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 244, 244]           1,792\n","              ReLU-2         [-1, 64, 244, 244]               0\n","            Conv2d-3         [-1, 64, 244, 244]          36,928\n","              ReLU-4         [-1, 64, 244, 244]               0\n","         MaxPool2d-5         [-1, 64, 122, 122]               0\n","            Conv2d-6        [-1, 128, 122, 122]          73,856\n","              ReLU-7        [-1, 128, 122, 122]               0\n","            Conv2d-8        [-1, 128, 122, 122]         147,584\n","              ReLU-9        [-1, 128, 122, 122]               0\n","        MaxPool2d-10          [-1, 128, 61, 61]               0\n","           Conv2d-11          [-1, 256, 61, 61]         295,168\n","             ReLU-12          [-1, 256, 61, 61]               0\n","           Conv2d-13          [-1, 256, 61, 61]         590,080\n","             ReLU-14          [-1, 256, 61, 61]               0\n","        MaxPool2d-15          [-1, 256, 30, 30]               0\n","           Conv2d-16          [-1, 512, 30, 30]       1,180,160\n","             ReLU-17          [-1, 512, 30, 30]               0\n","           Conv2d-18          [-1, 512, 30, 30]       2,359,808\n","             ReLU-19          [-1, 512, 30, 30]               0\n","        MaxPool2d-20          [-1, 512, 15, 15]               0\n","           Conv2d-21          [-1, 512, 15, 15]       2,359,808\n","             ReLU-22          [-1, 512, 15, 15]               0\n","           Conv2d-23          [-1, 512, 15, 15]       2,359,808\n","             ReLU-24          [-1, 512, 15, 15]               0\n","        MaxPool2d-25            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-26            [-1, 512, 7, 7]               0\n","           Linear-27                 [-1, 4096]     102,764,544\n","             ReLU-28                 [-1, 4096]               0\n","          Dropout-29                 [-1, 4096]               0\n","           Linear-30                 [-1, 4096]      16,781,312\n","             ReLU-31                 [-1, 4096]               0\n","          Dropout-32                 [-1, 4096]               0\n","           Linear-33                 [-1, 1000]       4,097,000\n","================================================================\n","Total params: 133,047,848\n","Trainable params: 133,047,848\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.68\n","Forward/backward pass size (MB): 235.19\n","Params size (MB): 507.54\n","Estimated Total Size (MB): 743.40\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# Initialize VGG-13 model\n","num_ftrs = model.classifier[6].in_features\n","model.classifier[6] = nn.Linear(num_ftrs, len(train_dataset.classes))\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239},"id":"pFYfK3gkjplH","executionInfo":{"status":"error","timestamp":1679392885747,"user_tz":-60,"elapsed":36,"user":{"displayName":"Keon Chen","userId":"05913365539252419352"}},"outputId":"76445ba9-161b-4536-e32d-6d646b090dcb"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-5632b47abc41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize VGG-13 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"]}]},{"cell_type":"code","source":["# Set loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"],"metadata":{"id":"EddAU5UWjycw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    running_corrects = 0\n","    grads = ''\n","\n","    for inputs, labels in train_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        loss = criterion(outputs, labels)\n","\n","        loss.backward()\n","\n","        # Calculate gradients and store them\n","        grads = param.grad.data.view(-1).clone().cpu() for param in model.parameters() if param.grad is not None\n","        break\n","\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / len(train_dataset)\n","    epoch_acc = running_corrects.double() / len(train_dataset)\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n","\n","\n","    # Calculate average gradient for the epoch\n","    # grads = torch.cat(grads)\n","    avg_grad = torch.mean(grads).item()\n","    print(f\"Epoch {epoch+1} - Average Gradient:\", avg_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239},"id":"j83SU4dVj7IT","executionInfo":{"status":"error","timestamp":1679392018211,"user_tz":-60,"elapsed":33,"user":{"displayName":"Keon Chen","userId":"05913365539252419352"}},"outputId":"fa0d9d93-e711-43f9-bf94-08653387e265"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-68277a6a3310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"]}]},{"cell_type":"code","source":["def compute_loss_and_gradient(model, data, target):\n","    # Compute the loss and gradient of the model on a single batch\n","    model.eval()\n","    loss_fn = nn.CrossEntropyLoss()\n","    data, target = data.to(device), target.to(device)\n","    data.requires_grad_()\n","    output = model(data)\n","    loss = loss_fn(output, target)\n","    loss.backward()\n","    grad = data.grad.clone().detach()\n","    return loss.item(), grad\n","\n","def determine_g(model, data_loader):\n","    # Determine g_m_c for each sample m and class c in the output layer\n","    model.eval()\n","    r_c_list = []\n","    for batch_idx, (data, target) in enumerate(data_loader):\n","        _, G_H = compute_loss_and_gradient(model, data, target)\n","        r_c_list.append(G_H[1:] / G_H[0])\n","        if batch_idx >= 10:  # Only use first 10 batches for efficiency\n","            break\n","    r_c = torch.cat(r_c_list)\n","    \n","    index_groups = []\n","    for j in range(r_c.shape[0]):\n","        found_group = False\n","        for i, index_group in enumerate(index_groups):\n","            if torch.allclose(r_c[j], r_c[index_group[0]]):\n","                index_groups[i].append(j)\n","                found_group = True\n","                break\n","        if not found_group:\n","            index_groups.append([j])\n","    \n","    g = torch.zeros((len(data_loader.dataset), r_c.shape[0]))\n","    for batch_idx, (data, target) in enumerate(data_loader):\n","        data = data.to(device)\n","        output = model(data)\n","        prob = F.softmax(output, dim=1)\n","        for c in range(r_c.shape[0]):\n","            j = index_groups[batch_idx % len(index_groups)][c]\n","            g[batch_idx*len(data):(batch_idx+1)*len(data)][c] = prob[:, j] / prob[:, 0]\n","    \n","    return g"],"metadata":{"id":"1DSfL9voyxMO"},"execution_count":null,"outputs":[]}]}